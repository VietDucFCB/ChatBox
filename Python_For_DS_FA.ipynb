{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for Data Science\n",
    "## Final Assignment: AI Engineer Assignment\n",
    "### Group:\n",
    "- Nguyễn Minh Đạt - 22280009\n",
    "- Nguyễn Xuân Việt Đức - 22280012\n",
    "- Lê Đức Hòa - 22280027"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aXlEYUDmw1W8",
    "outputId": "0b6346a6-5863-4b68-f012-ca162e181191"
   },
   "outputs": [],
   "source": [
    "!pip install selenium\n",
    "!apt-get update\n",
    "!apt install chromium-chromedriver\n",
    "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
    "!pip install -U langchain-community\n",
    "!pip install langchain openai faiss-cpu\n",
    "!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "10MWxQmown8C"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import textwrap\n",
    "from typing import List, Optional\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.base import Embeddings\n",
    "import google.generativeai as genai\n",
    "from google.colab import userdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: LLM integration (Score: 30%)\n",
    "The task involves building an AI capable of language translation.\n",
    "\n",
    "### 1.1 Single Text Translation: (Score: 15%)\n",
    "You are asked to write a Python code using the OpenAI API to translate a given text into Vietnamese \n",
    "(You should check the text if it’s already the destination language .\n",
    "For example, translating \"Hello\" into Vietnamese should return \"Xin chào\", but “Xin chào” sho ld\n",
    "return the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "id": "24xasbi8b2VG",
    "outputId": "0cb3a545-8b9d-49f0-a398-849d97e1d592"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter text to translate (or type 'quit' to exit): Xin chào\n",
      "Result: Xin chào\n",
      "\n",
      "Enter text to translate (or type 'quit' to exit): Hello\n",
      "Result: Xin chào\n",
      "\n",
      "Enter text to translate (or type 'quit' to exit): quit\n",
      "Exiting program.\n"
     ]
    }
   ],
   "source": [
    "def translate_to_vietnamese(text: str) -> Optional[str]:\n",
    "    try:\n",
    "        # Get API key from environment variable\n",
    "        api_key= os.getenv('GEMINI_API_KEY')\n",
    "        if not api_key:\n",
    "            raise ValueError(\"Missing API key. Set GEMINI_API_KEY environment variable\")\n",
    "\n",
    "        # Configure the API\n",
    "        genai.configure(api_key=api_key)\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "        # Create the prompt\n",
    "        prompt = \"Translate this text to Vietnamese. If it's already in Vietnamese, return it unchanged..\"\n",
    "\n",
    "        # Generate the translation\n",
    "        response = model.generate_content(\n",
    "        prompt + text,\n",
    "        generation_config={\n",
    "                \"temperature\": 0,  # creative\n",
    "                \"top_p\": 0         # nucleus sampling.\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return response.text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Translation error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        text = input(\"Enter text to translate (or type 'quit' to exit): \").strip()\n",
    "        if text.lower() == \"quit\":\n",
    "            print(\"Exiting program.\")\n",
    "            break\n",
    "\n",
    "        result = translate_to_vietnamese(text)\n",
    "        if result:\n",
    "            print(\"Result:\", result)\n",
    "        else:\n",
    "            print(\"Translation failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Multiple Texts Translation: (Score: 15%)\n",
    "Similar to 2.1, but the input is a list of texts. The Python code should accept a list of strings and return their translations in the specified language. For instance, translating \n",
    "[\"Hello\", \"I am John\", “Tôi là sinh viên”] into Vietnamese should return [\"Xin chào\", \"Tôi tên là John\", “Tôi là sinh viên”]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "CEfXS0wiXw6F",
    "outputId": "fc3ff747-e045-4cbd-b491-26e3d1d43e5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Xin chào', 'Tôi là John', 'Tôi là sinh viên']\n",
      "Original: Hello\n",
      "Translated: Xin chào\n",
      "------------------------------\n",
      "Original: I am John\n",
      "Translated: Tôi là John\n",
      "------------------------------\n",
      "Original: Tôi là sinh viên\n",
      "Translated: Tôi là sinh viên\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "def translate_texts_to_vietnamese(texts: List[str], api_key: str) -> List[str]:\n",
    "  translations = []\n",
    "  for text in texts:\n",
    "    try:\n",
    "        # Get API key from environment variable\n",
    "        api_key= os.getenv('GEMINI_API_KEY')\n",
    "        if not api_key:\n",
    "            raise ValueError(\"Missing API key. Set GEMINI_API_KEY environment variable\")\n",
    "\n",
    "        # Configure the API\n",
    "        genai.configure(api_key=api_key)\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "        # Create the prompt\n",
    "        prompt = \"Translate this text to Vietnamese. If it's already in Vietnamese, return it unchanged: \"\n",
    "\n",
    "        # Generate the translation\n",
    "        response = model.generate_content(prompt + text)\n",
    "        translated_text = response.text.strip()\n",
    "\n",
    "        # Add to results\n",
    "        translations.append(translated_text)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Translation error: {str(e)}\")\n",
    "  return translations\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Your API key\n",
    "    api_key = os.getenv('GEMINI_API_KEY')\n",
    "    # Example texts\n",
    "    sample_texts = [\"Hello\", \"I am John\", \"Tôi là sinh viên\"]\n",
    "\n",
    "    # Get translations\n",
    "    translated_texts = translate_texts_to_vietnamese(sample_texts, api_key)\n",
    "\n",
    "    # Print results\n",
    "    print (translated_texts)\n",
    "    for original, translated in zip(sample_texts, translated_texts):\n",
    "        print(f\"Original: {original}\")\n",
    "        print(f\"Translated: {translated}\")\n",
    "        print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Chatbot Development (Score: 70%)\n",
    "Assignment Test: Chatbot Development from Website Data. The data is at [https://www.presight.io/privacy-policy.html]\n",
    "### 2.1 Data Access and Indexing (Score: 40%)\n",
    "Tasked with creating a chatbot, begin by web crawling the specified website to gather relevant data, then preprocess and structure this data into a searchable index, ready for query retrieval. (Short version: crawling then embedding data, you can use selenium or requests)\n",
    "\n",
    "### 2.2 Chatbot Development (Score: 30%)\n",
    "Develop a chatbot that employs natural language processing to comprehend user questions, searches the indexed data from 2.1 for the best match, and delivers the most accurate response drawn from the website's information. (Use any distance/similarity metrics to get the best match paragraph then feed to LLM to get answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YyQ8tvMdSsM2",
    "outputId": "da84a80f-d3e8-4371-c8c3-193d6dc263aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing vector store...\n",
      "Vector store loaded successfully!\n",
      "\n",
      "Chatbot is ready! Type 'quit' to stop.\n",
      "\n",
      "You: what is policy\n",
      "\n",
      "Answer: The provided text describes Presight's privacy policy.  Key aspects include:  * **Information Collection and Use:** Presight collects personal\n",
      "data (email, name, phone, address, etc.) and usage data (IP address, browser type, etc.) to provide and improve its service (Sections: Information\n",
      "Collection and Use, Types of Data Collected, Use of Data).  They use automated edit checks to ensure data accuracy (Section: Automated Edit Checks).\n",
      "* **Data Security:**  Data is encrypted in transit and at rest; security audits are performed; employee access is restricted (Section: Data Security).\n",
      "* **Data Retention and Disposal:** Data is retained while an account is active, then for 60 days after closure before removal (Section: Data Retention\n",
      "& Disposal).  * **Data Subject Responsibilities:** Users are responsible for providing accurate information and notifying Presight of any inaccuracies\n",
      "(Section: Quality, Including Data Subjects' Responsibilities for Quality).  * **Third-Party Sharing:**  Presight may disclose data to service\n",
      "providers (Datadog, AWS, Google Cloud, Google Workspace) and in response to legal requests (Section: Disclosure of Information).  However, they do\n",
      "*not* share personal data with third parties for AI model development (Section: Sharing of Personal Data).  They also specify that Google User Data is\n",
      "not transferred to third-party AI tools for AI model development (Section: Google User Data and Google Workspace APIs).  * **User Access to Data:**\n",
      "Users can access, correct, amend, or append their personal information through the application (Section: Access to Personal Information).  *\n",
      "**Compliance:** Presight is committed to complying with data protection laws and cooperating with data protection authorities (Section: Monitoring and\n",
      "Enforcement).  * **Cookies:** Presight uses cookies to enhance website experience, controllable through browser settings (Section: Cookies).  *\n",
      "**Third-Party Websites:** Presight is not responsible for the privacy practices of linked third-party websites (Section: Third-Party Websites).  *\n",
      "**Policy Updates:** The policy may be updated from time to time (Section: Changes to Privacy Policy).  The last update was September 15, 2023\n",
      "(Section: PRIVACY POLICY).\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "You: how do i get in touch with you\n",
      "\n",
      "Answer: You can contact Presight through the customer portal or by email at presight@presight.io.  (Contact Us section)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "You: when was the last update date\n",
      "\n",
      "Answer: The last update date of the privacy policy is September 15, 2023.  This is stated in the \"PRIVACY POLICY\" section.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "You: what is a cookie policy\n",
      "\n",
      "Answer: The provided text states, in the \"Cookies\" section, that \"We use cookies to enhance your experience on our website. You can control the use of\n",
      "cookies through your web browser settings.\"  No further details on a specific cookie policy are available in the provided sections.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "You: is there any risk of third-party software caused by cookies\n",
      "\n",
      "Answer: The provided text mentions that cookies are used to enhance the website experience (\"Cookies\" section), and that users can control cookie use\n",
      "through their browser settings.  However, there is no information about the risk of third-party software caused by cookies.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "You: can personal information be leaked\n",
      "\n",
      "Answer: The provided text states that in the event of a data breach or unauthorized access to personal information, Presight will notify users and the\n",
      "appropriate authorities as required by law (Monitoring and Enforcement section).  However, it does not explicitly state that personal information\n",
      "*can* be leaked, only that Presight has procedures in place to address breaches if they occur.  The policy also describes security measures such as\n",
      "data encryption (Data Security section).\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "You: quit\n",
      "Thank you for using the chatbot. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "def crawl_data_with_selenium(url):\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36\")\n",
    "    chrome_options.add_argument(\"webdriver.chrome.driver=/usr/lib/chromium-browser/chromedriver\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        h2_elements = driver.find_elements(By.TAG_NAME, \"h2\")\n",
    "        result = []\n",
    "        concatenated_text = \"\"\n",
    "\n",
    "        # Fetch the entire content of the page\n",
    "        body_text = driver.find_element(By.TAG_NAME, \"body\").text\n",
    "        concatenated_text = body_text.strip()\n",
    "\n",
    "        for h2 in h2_elements:\n",
    "            h2_text = h2.text\n",
    "            try:\n",
    "                next_sibling = h2.find_element(By.XPATH, \"following-sibling::*\")\n",
    "                sibling_text = next_sibling.text\n",
    "            except:\n",
    "                sibling_text = \"\"\n",
    "            result.append({\"h2\": h2_text, \"content\": sibling_text})\n",
    "\n",
    "        output = {\n",
    "            \"data\": result,\n",
    "            \"concatenatedText\": concatenated_text\n",
    "        }\n",
    "\n",
    "        # Save the output object to a JSON file\n",
    "        output_file = \"result.json\"\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(output, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        return output\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "# Gemini Embeddings Class\n",
    "class GeminiEmbeddings(Embeddings):\n",
    "    def embed_documents(self, texts):\n",
    "        embeddings = []\n",
    "        for text in texts:\n",
    "            result = genai.embed_content(\n",
    "                model=\"models/text-embedding-004\",\n",
    "                content=text\n",
    "            )\n",
    "            embeddings.append(result['embedding'])\n",
    "        return embeddings\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        result = genai.embed_content(\n",
    "            model=\"models/text-embedding-004\",\n",
    "            content=text\n",
    "        )\n",
    "        return result['embedding']\n",
    "\n",
    "# Function to process and vectorize extracted data\n",
    "def process_extracted_data(data):\n",
    "    text_contents = []\n",
    "    for item in data['data']:\n",
    "        combined_text = f\"Section: {item['h2']}\\nContent: {item['content']}\"\n",
    "        text_contents.append(combined_text)\n",
    "\n",
    "    # add concatenatedText to enrich the context\n",
    "    text_contents.append(data['concatenatedText'])\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=100,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    "    )\n",
    "    chunks = text_splitter.split_text('\\n'.join(text_contents))\n",
    "    embeddings = GeminiEmbeddings()\n",
    "    vectorstore = FAISS.from_texts(chunks, embeddings)\n",
    "\n",
    "    return vectorstore\n",
    "\n",
    "    return vectorstore\n",
    "\n",
    "# Function to generate chatbot responses\n",
    "def get_chatbot_response(query, relevant_text, model_name):\n",
    "    prompt = f\"\"\"Based on the following privacy policy sections, please provide a clear and direct answer to the question. If the information is not found in the provided sections, please state that clearly.\n",
    "\n",
    "    Privacy Policy Sections:\n",
    "    {relevant_text}\n",
    "\n",
    "    Question: {query}\n",
    "\n",
    "    Instructions:\n",
    "    - Use only information from the provided sections\n",
    "    - Be specific and cite the relevant sections when possible\n",
    "    - If information is not found, say so clearly\n",
    "    \"\"\"\n",
    "\n",
    "    model = genai.GenerativeModel(model_name)\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "# Function to process a query\n",
    "def process_query(vectorstore, query, model_name):\n",
    "    k = 15  # add more text chunks to retrieve\n",
    "\n",
    "    #similarity searching\n",
    "    results = vectorstore.similarity_search(query, k=k)\n",
    "    relevant_texts = [doc.page_content for doc in results]\n",
    "\n",
    "    # add weights\n",
    "    query_terms = query.lower().split()\n",
    "    weighted_texts = []\n",
    "\n",
    "    for text in relevant_texts:\n",
    "        score = 0\n",
    "        text_lower = text.lower()\n",
    "        for term in query_terms:\n",
    "            if term in text_lower:\n",
    "                score += 1\n",
    "        weighted_texts.append((text, score))\n",
    "\n",
    "    # Sắp xếp theo trọng số và lấy top k kết quả\n",
    "    weighted_texts.sort(key=lambda x: x[1], reverse=True)\n",
    "    final_texts = [text for text, _ in weighted_texts[:k]]\n",
    "\n",
    "    relevant_text = \"\\n\\n\".join(final_texts)\n",
    "    answer = get_chatbot_response(query, relevant_text, model_name)\n",
    "\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"relevant_texts\": final_texts,\n",
    "        \"answer\": answer\n",
    "    }\n",
    "\n",
    "\n",
    "# Function to print wrapped text with separator\n",
    "def print_wrapped_text_with_separator(text, width=150):\n",
    "    wrapper = textwrap.TextWrapper(width=width)\n",
    "    wrapped_text = wrapper.fill(text)\n",
    "    print(\"\\n\" + wrapped_text + \"\\n\" + \"-\" * width + \"\\n\")\n",
    "\n",
    "def main():\n",
    "    os.environ['GEMINI_API_KEY'] = userdata.get('GEMINI_API_KEY')\n",
    "    genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "    url = \"https://www.presight.io/privacy-policy.html\"\n",
    "    vectorstore_path = \"vectorstore_faiss_index\"\n",
    "    model_name = \"gemini-1.5-flash\"\n",
    "\n",
    "    try:\n",
    "        if os.path.exists(vectorstore_path):\n",
    "            print(\"Loading existing vector store...\")\n",
    "            embeddings = GeminiEmbeddings()\n",
    "            vectorstore = FAISS.load_local(vectorstore_path, embeddings, allow_dangerous_deserialization=True)\n",
    "            print(\"Vector store loaded successfully!\\n\")\n",
    "        else:\n",
    "            print(\"Crawling and processing content...\")\n",
    "            data = crawl_data_with_selenium(url)\n",
    "            vectorstore = process_extracted_data(data)\n",
    "            vectorstore.save_local(vectorstore_path)\n",
    "            print(\"Content processed successfully!\\n\")\n",
    "\n",
    "        print(\"Chatbot is ready! Type 'quit' to stop.\\n\")\n",
    "        while True:\n",
    "            try:\n",
    "                query = input(\"You: \").strip()\n",
    "                if query.lower() == 'quit':\n",
    "                    print(\"Thank you for using the chatbot. Goodbye!\")\n",
    "                    break\n",
    "\n",
    "                if not query:\n",
    "                    print(\"Please enter a valid question.\")\n",
    "                    continue\n",
    "\n",
    "                results = process_query(vectorstore, query, model_name)\n",
    "                if not results['relevant_texts']:\n",
    "                    print(\"\\nNo relevant information found. Please try rephrasing your question.\")\n",
    "                    continue\n",
    "\n",
    "                # Print the answer with formatting and separator\n",
    "                print_wrapped_text_with_separator(f\"Answer: {results['answer']}\\n\", width=150)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing query: {str(e)}\")\n",
    "                print(\"Please try another question.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Critical error: {str(e)}\")\n",
    "        print(\"Please restart the application.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
